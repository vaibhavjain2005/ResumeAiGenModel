{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15Fci2qCO1dA5xvLEaTi3v_9DbRE67tHJ",
      "authorship_tag": "ABX9TyM0rskyIpIf0vedhGSWajuU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhavjain2005/ResumeAiGenModel/blob/main/final_resume.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask pyngrok transformers torch sentencepiece reportlab -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p4DXjd8K7-w",
        "outputId": "f1bc7c43-0e6b-49ca-af20-e73d847c7bda"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/2.0 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import io\n",
        "from flask import Flask, request, jsonify, send_file\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.lib.units import inch\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\n",
        "from reportlab.lib.enums import TA_LEFT, TA_CENTER\n",
        "from reportlab.lib import colors\n",
        "from datetime import datetime\n",
        "import json"
      ],
      "metadata": {
        "id": "gOa4n_l8M-Gp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "print(\"Loading FLAN-T5-Large model... (better quality, still free)\")\n",
        "model_path = \"./flan-t5-base-resume-finetuned-stable/final_model\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
        "print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A_2faxsM_ZF",
        "outputId": "63b7e50b-a31f-4fa8-8e06-b047011b68b0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading FLAN-T5-Large model... (better quality, still free)\n",
            "‚úÖ Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #AI Functions for Resume Generation\n",
        "def extract_keywords_from_job(job_description):\n",
        "    \"\"\"Extract important keywords from job description\"\"\"\n",
        "    prompt = f\"\"\"Extract key skills and technologies from this job posting. List only the most important ones as comma-separated keywords.\n",
        "\n",
        "Job Description: {job_description}\n",
        "\n",
        "Important keywords:\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=100,\n",
        "        num_beams=4,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    keywords = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return keywords.strip()\n",
        "\n",
        "\n",
        "def tailor_resume_experience(experience_text, keywords):\n",
        "    \"\"\"Rewrite experience bullet to match job requirements\"\"\"\n",
        "    prompt = f\"\"\"Rewrite this work experience bullet point to be professional and impactful. Use action verbs and be specific.\n",
        "\n",
        "Original: {experience_text}\n",
        "\n",
        "Improved bullet point:\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=100,\n",
        "        num_beams=4,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    improved = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # If the output is too similar to input or just keywords, return improved original\n",
        "    if len(improved) < 10 or improved == keywords:\n",
        "        return experience_text\n",
        "    return improved.strip()\n",
        "\n",
        "\n",
        "def tailor_project_description(project_desc, project_tech, keywords):\n",
        "    \"\"\"Enhance project description to highlight relevant skills\"\"\"\n",
        "    prompt = f\"\"\"Rewrite this project description to be more professional and highlight technical achievements.\n",
        "\n",
        "Project: {project_desc}\n",
        "Technologies: {project_tech}\n",
        "\n",
        "Enhanced description:\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=100,\n",
        "        num_beams=4,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    improved = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # If output is too short or generic, return original\n",
        "    if len(improved) < 15:\n",
        "        return project_desc\n",
        "    return improved.strip()\n",
        "\n",
        "\n",
        "def generate_professional_summary(user_data, keywords, job_description):\n",
        "    \"\"\"Generate a professional summary tailored to the job\"\"\"\n",
        "    # Get actual experience details\n",
        "    exp_count = len(user_data.get('experience', []))\n",
        "    skills = user_data.get('skills', [])[:6]\n",
        "\n",
        "    # Get first job title if available\n",
        "    first_role = \"Professional\"\n",
        "    if user_data.get('experience') and len(user_data['experience']) > 0:\n",
        "        first_role = user_data['experience'][0].get('title', 'Professional')\n",
        "\n",
        "    prompt = f\"\"\"Write a professional resume summary for someone with these qualifications:\n",
        "Role: {first_role}\n",
        "Years of experience: {exp_count} positions\n",
        "Skills: {', '.join(skills)}\n",
        "\n",
        "Write a 2-3 sentence professional summary:\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=120,\n",
        "        num_beams=4,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True,\n",
        "        length_penalty=1.0\n",
        "    )\n",
        "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Fallback if AI generates poor summary\n",
        "    if len(summary) < 30 or \"job requirements\" in summary.lower():\n",
        "        summary = f\"Results-driven {first_role} with experience in {', '.join(skills[:3])}. Proven track record of delivering high-quality solutions and collaborating with cross-functional teams.\"\n",
        "\n",
        "    return summary.strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "u8EeBqATPMRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_professional_resume_pdf(resume_data):\n",
        "    \"\"\"Generate a professional, ATS-friendly PDF resume\"\"\"\n",
        "    buffer = io.BytesIO()\n",
        "    doc = SimpleDocTemplate(buffer, pagesize=letter,\n",
        "                           rightMargin=0.75*inch, leftMargin=0.75*inch,\n",
        "                           topMargin=0.75*inch, bottomMargin=0.75*inch)\n",
        "\n",
        "    story = []\n",
        "    styles = getSampleStyleSheet()\n",
        "\n",
        "\n",
        "    title_style = ParagraphStyle(\n",
        "        'CustomTitle',\n",
        "        parent=styles['Heading1'],\n",
        "        fontSize=24,\n",
        "        textColor=colors.HexColor('#2C3E50'),\n",
        "        spaceAfter=6,\n",
        "        alignment=TA_CENTER,\n",
        "        fontName='Helvetica-Bold'\n",
        "    )\n",
        "\n",
        "    contact_style = ParagraphStyle(\n",
        "        'Contact',\n",
        "        parent=styles['Normal'],\n",
        "        fontSize=10,\n",
        "        textColor=colors.HexColor('#34495E'),\n",
        "        alignment=TA_CENTER,\n",
        "        spaceAfter=20\n",
        "    )\n",
        "\n",
        "    section_header_style = ParagraphStyle(\n",
        "        'SectionHeader',\n",
        "        parent=styles['Heading2'],\n",
        "        fontSize=14,\n",
        "        textColor=colors.HexColor('#2C3E50'),\n",
        "        spaceAfter=12,\n",
        "        spaceBefore=12,\n",
        "        fontName='Helvetica-Bold',\n",
        "        borderWidth=1,\n",
        "        borderColor=colors.HexColor('#3498DB'),\n",
        "        borderPadding=5,\n",
        "        backColor=colors.HexColor('#ECF0F1')\n",
        "    )\n",
        "\n",
        "    body_style = ParagraphStyle(\n",
        "        'CustomBody',\n",
        "        parent=styles['Normal'],\n",
        "        fontSize=10,\n",
        "        textColor=colors.HexColor('#2C3E50'),\n",
        "        spaceAfter=6,\n",
        "        leading=14\n",
        "    )\n",
        "\n",
        "    # Personal Information\n",
        "    personal = resume_data.get('personal_info', {})\n",
        "    story.append(Paragraph(personal.get('name', 'Your Name'), title_style))\n",
        "\n",
        "    contact_info = f\"{personal.get('email', '')} | {personal.get('phone', '')} | {personal.get('location', '')}\"\n",
        "    if personal.get('linkedin'):\n",
        "        contact_info += f\" | LinkedIn: {personal.get('linkedin')}\"\n",
        "    story.append(Paragraph(contact_info, contact_style))\n",
        "\n",
        "    # Professional Summary\n",
        "    if resume_data.get('professional_summary'):\n",
        "        story.append(Paragraph(\"PROFESSIONAL SUMMARY\", section_header_style))\n",
        "        story.append(Paragraph(resume_data['professional_summary'], body_style))\n",
        "        story.append(Spacer(1, 0.2*inch))\n",
        "\n",
        "    # Skills\n",
        "    if resume_data.get('skills'):\n",
        "        story.append(Paragraph(\"SKILLS\", section_header_style))\n",
        "        skills_text = \" ‚Ä¢ \".join(resume_data['skills'])\n",
        "        story.append(Paragraph(skills_text, body_style))\n",
        "        story.append(Spacer(1, 0.2*inch))\n",
        "\n",
        "    # Experience\n",
        "    if resume_data.get('experience'):\n",
        "        story.append(Paragraph(\"PROFESSIONAL EXPERIENCE\", section_header_style))\n",
        "        for exp in resume_data['experience']:\n",
        "            job_title = f\"<b>{exp.get('title', 'Position')}</b> | {exp.get('company', 'Company')}\"\n",
        "            story.append(Paragraph(job_title, body_style))\n",
        "\n",
        "            duration = f\"<i>{exp.get('start_date', '')} - {exp.get('end_date', 'Present')} | {exp.get('location', '')}</i>\"\n",
        "            story.append(Paragraph(duration, body_style))\n",
        "            story.append(Spacer(1, 0.1*inch))\n",
        "\n",
        "            for bullet in exp.get('bullets', []):\n",
        "                bullet_text = f\"‚Ä¢ {bullet}\"\n",
        "                story.append(Paragraph(bullet_text, body_style))\n",
        "\n",
        "            story.append(Spacer(1, 0.15*inch))\n",
        "\n",
        "    # Projects\n",
        "    if resume_data.get('projects'):\n",
        "        story.append(Paragraph(\"PROJECTS\", section_header_style))\n",
        "        for project in resume_data['projects']:\n",
        "            project_title = f\"<b>{project.get('name', 'Project')}</b>\"\n",
        "            if project.get('technologies'):\n",
        "                project_title += f\" | <i>{project.get('technologies')}</i>\"\n",
        "            story.append(Paragraph(project_title, body_style))\n",
        "\n",
        "            if project.get('description'):\n",
        "                story.append(Paragraph(f\"‚Ä¢ {project['description']}\", body_style))\n",
        "\n",
        "            story.append(Spacer(1, 0.1*inch))\n",
        "\n",
        "    # Education\n",
        "    if resume_data.get('education'):\n",
        "        story.append(Paragraph(\"EDUCATION\", section_header_style))\n",
        "        for edu in resume_data['education']:\n",
        "            edu_text = f\"<b>{edu.get('degree', 'Degree')}</b> | {edu.get('institution', 'Institution')}\"\n",
        "            story.append(Paragraph(edu_text, body_style))\n",
        "\n",
        "            edu_details = f\"<i>{edu.get('graduation_date', '')} | GPA: {edu.get('gpa', 'N/A')}</i>\"\n",
        "            story.append(Paragraph(edu_details, body_style))\n",
        "            story.append(Spacer(1, 0.1*inch))\n",
        "\n",
        "    # Build PDF\n",
        "    doc.build(story)\n",
        "    buffer.seek(0)\n",
        "    return buffer\n",
        "\n"
      ],
      "metadata": {
        "id": "_udDm9HLPW2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flask API\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return \"\"\"\n",
        "    <h1>üöÄ Enhanced Resume Generator API with PDF Export</h1>\n",
        "    <p>API is running! Generate professional resumes with AI.</p>\n",
        "    <h3>Endpoints:</h3>\n",
        "    <ul>\n",
        "        <li><b>POST /api/analyze-job</b> - Extract keywords from job description</li>\n",
        "        <li><b>POST /api/generate-resume</b> - Generate complete tailored resume (JSON)</li>\n",
        "        <li><b>POST /api/generate-resume-pdf</b> - Generate and download PDF resume</li>\n",
        "    </ul>\n",
        "    <p>Model: FLAN-T5-Large (Improved Quality)</p>\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "@app.route(\"/api/analyze-job\", methods=[\"POST\"])\n",
        "def analyze_job():\n",
        "    \"\"\"Extract keywords from job description\"\"\"\n",
        "    try:\n",
        "        data = request.json\n",
        "        job_description = data.get(\"job_description\", \"\")\n",
        "\n",
        "        if not job_description:\n",
        "            return jsonify({\"error\": \"job_description is required\"}), 400\n",
        "\n",
        "        keywords = extract_keywords_from_job(job_description)\n",
        "\n",
        "        return jsonify({\n",
        "            \"success\": True,\n",
        "            \"keywords\": keywords,\n",
        "            \"keywords_list\": [k.strip() for k in keywords.split(\",\") if k.strip()]\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "\n",
        "@app.route(\"/api/generate-resume\", methods=[\"POST\"])\n",
        "def generate_resume():\n",
        "    \"\"\"Generate a complete tailored resume (JSON response)\"\"\"\n",
        "    try:\n",
        "        data = request.json\n",
        "\n",
        "        job_description = data.get(\"job_description\", \"\")\n",
        "        personal_info = data.get(\"personal_info\", {})\n",
        "        education = data.get(\"education\", [])\n",
        "        experience = data.get(\"experience\", [])\n",
        "        projects = data.get(\"projects\", [])\n",
        "        skills = data.get(\"skills\", [])\n",
        "\n",
        "        if not job_description:\n",
        "            return jsonify({\"error\": \"job_description is required\"}), 400\n",
        "\n",
        "        keywords = extract_keywords_from_job(job_description)\n",
        "        keywords_list = [k.strip() for k in keywords.split(\",\") if k.strip()]\n",
        "\n",
        "        # Generate professional summary\n",
        "        user_background = {\n",
        "            \"experience\": experience,\n",
        "            \"skills\": skills\n",
        "        }\n",
        "        professional_summary = generate_professional_summary(user_background, keywords, job_description)\n",
        "\n",
        "        # Tailor experience bullets\n",
        "        tailored_experience = []\n",
        "        for exp in experience:\n",
        "            tailored_bullets = []\n",
        "            for bullet in exp.get(\"bullets\", []):\n",
        "                # Only tailor if bullet is substantial\n",
        "                if len(bullet) > 10:\n",
        "                    improved = tailor_resume_experience(bullet, keywords)\n",
        "                    tailored_bullets.append(improved)\n",
        "                else:\n",
        "                    tailored_bullets.append(bullet)\n",
        "\n",
        "            tailored_experience.append({\n",
        "                **exp,\n",
        "                \"bullets\": tailored_bullets\n",
        "            })\n",
        "\n",
        "        # Tailor project descriptions\n",
        "        tailored_projects = []\n",
        "        for project in projects:\n",
        "            tailored_desc = project.get(\"description\", \"\")\n",
        "            if len(tailored_desc) > 15:\n",
        "                tailored_desc = tailor_project_description(\n",
        "                    project.get(\"description\", \"\"),\n",
        "                    project.get(\"technologies\", \"\"),\n",
        "                    keywords\n",
        "                )\n",
        "\n",
        "            tailored_projects.append({\n",
        "                **project,\n",
        "                \"description\": tailored_desc\n",
        "            })\n",
        "\n",
        "        # Match score\n",
        "        match_score = 0\n",
        "        if keywords_list and skills:\n",
        "            matched = sum(1 for k in keywords_list if any(k.lower() in s.lower() for s in skills))\n",
        "            match_score = (matched / len(keywords_list)) * 100\n",
        "\n",
        "        resume_data = {\n",
        "            \"success\": True,\n",
        "            \"keywords_extracted\": keywords_list,\n",
        "            \"professional_summary\": professional_summary,\n",
        "            \"personal_info\": personal_info,\n",
        "            \"education\": education,\n",
        "            \"experience\": tailored_experience,\n",
        "            \"projects\": tailored_projects,\n",
        "            \"skills\": skills,\n",
        "            \"match_score\": round(match_score, 1)\n",
        "        }\n",
        "\n",
        "        return jsonify(resume_data)\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "\n",
        "@app.route(\"/api/generate-resume-pdf\", methods=[\"POST\"])\n",
        "def generate_resume_pdf():\n",
        "    \"\"\"Generate and download professional PDF resume\"\"\"\n",
        "    try:\n",
        "        data = request.json\n",
        "\n",
        "        job_description = data.get(\"job_description\", \"\")\n",
        "        personal_info = data.get(\"personal_info\", {})\n",
        "        education = data.get(\"education\", [])\n",
        "        experience = data.get(\"experience\", [])\n",
        "        projects = data.get(\"projects\", [])\n",
        "        skills = data.get(\"skills\", [])\n",
        "\n",
        "        if not job_description:\n",
        "            return jsonify({\"error\": \"job_description is required\"}), 400\n",
        "\n",
        "        # keyword extraction\n",
        "        keywords = extract_keywords_from_job(job_description)\n",
        "        user_background = {\"experience\": experience, \"skills\": skills}\n",
        "        professional_summary = generate_professional_summary(user_background, keywords, job_description)\n",
        "\n",
        "        # detailing more about prof exp\n",
        "        tailored_experience = []\n",
        "        for exp in experience:\n",
        "            tailored_bullets = []\n",
        "            for bullet in exp.get(\"bullets\", []):\n",
        "                if len(bullet) > 10:\n",
        "                    improved = tailor_resume_experience(bullet, keywords)\n",
        "                    tailored_bullets.append(improved)\n",
        "                else:\n",
        "                    tailored_bullets.append(bullet)\n",
        "            tailored_experience.append({**exp, \"bullets\": tailored_bullets})\n",
        "\n",
        "        # project descriptions boasting them\n",
        "        tailored_projects = []\n",
        "        for project in projects:\n",
        "            tailored_desc = project.get(\"description\", \"\")\n",
        "            if len(tailored_desc) > 15:\n",
        "                tailored_desc = tailor_project_description(\n",
        "                    project.get(\"description\", \"\"),\n",
        "                    project.get(\"technologies\", \"\"),\n",
        "                    keywords\n",
        "                )\n",
        "            tailored_projects.append({**project, \"description\": tailored_desc})\n",
        "\n",
        "\n",
        "        resume_data = {\n",
        "            \"professional_summary\": professional_summary,\n",
        "            \"personal_info\": personal_info,\n",
        "            \"education\": education,\n",
        "            \"experience\": tailored_experience,\n",
        "            \"projects\": tailored_projects,\n",
        "            \"skills\": skills\n",
        "        }\n",
        "\n",
        "        # Generate PDF\n",
        "        pdf_buffer = create_professional_resume_pdf(resume_data)\n",
        "\n",
        "        filename = f\"Resume_{personal_info.get('name', 'User').replace(' ', '_')}_{datetime.now().strftime('%Y%m%d')}.pdf\"\n",
        "\n",
        "        return send_file(\n",
        "            pdf_buffer,\n",
        "            mimetype='application/pdf',\n",
        "            as_attachment=True,\n",
        "            download_name=filename\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n"
      ],
      "metadata": {
        "id": "eKZyvxnhPg4o"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import threading\n",
        "\n",
        "ngrok.set_auth_token(\"34RuNCVR0o60Xl34SO01IPOJy0p_eu3CHpGA8gjg8sSYc1hR\")\n",
        "port = 5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"‚úÖ API is LIVE!\")\n",
        "print(f\"üåê Public URL: {public_url}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "threading.Thread(target=app.run, kwargs={\"port\": port}).start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdM8OzNBP1I2",
        "outputId": "b1e1d30b-9efa-4651-ecbc-87fde7ef99f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "‚úÖ API is LIVE!\n",
            "üåê Public URL: https://machinable-skyla-consortable.ngrok-free.dev\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10614f4d",
        "outputId": "946dcf92-c2fd-4f95-bebb-90f4838036f4"
      },
      "source": [
        "# ai generated code for testing of the api\n",
        "import requests\n",
        "import json\n",
        "\n",
        "api_url = \"https://machinable-skyla-consortable.ngrok-free.dev/\"\n",
        "\n",
        "# api testing due extra precaution\n",
        "print(\"=\"*50)\n",
        "print(\"Testing /api/analyze-job\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "job_description_data = {\n",
        "    \"job_description\": \"We are looking for a skilled Software Engineer with experience in Python, Django, and AWS to join our team. Responsibilities include developing web applications and contributing to cloud infrastructure.\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    response = requests.post(f\"{api_url}/api/analyze-job\", json=job_description_data)\n",
        "    response.raise_for_status() # Raise an exception for bad status codes\n",
        "    print(\"Response Status Code:\", response.status_code)\n",
        "    print(\"Response JSON:\")\n",
        "    print(json.dumps(response.json(), indent=2))\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error testing /api/analyze-job: {e}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# this sections is for resume generation phase\n",
        "print(\"=\"*50)\n",
        "print(\"Testing /api/generate-resume (JSON output)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "resume_input_data = {\n",
        "    \"job_description\": \"We are looking for a skilled Software Engineer with experience in Python, Django, and AWS to join our team. Responsibilities include developing web applications and contributing to cloud infrastructure.\",\n",
        "    \"personal_info\": {\n",
        "        \"name\": \"Jane Doe\",\n",
        "        \"email\": \"jane.doe@example.com\",\n",
        "        \"phone\": \"123-456-7890\",\n",
        "        \"location\": \"San Francisco, CA\",\n",
        "        \"linkedin\": \"linkedin.com/in/janedoe\"\n",
        "    },\n",
        "    \"education\": [\n",
        "        {\n",
        "            \"degree\": \"Master of Science in Computer Science\",\n",
        "            \"institution\": \"University of California, Berkeley\",\n",
        "            \"graduation_date\": \"May 2022\",\n",
        "            \"gpa\": \"3.9\"\n",
        "        },\n",
        "        {\n",
        "            \"degree\": \"Bachelor of Science in Electrical Engineering\",\n",
        "            \"institution\": \"Stanford University\",\n",
        "            \"graduation_date\": \"May 2020\",\n",
        "            \"gpa\": \"3.8\"\n",
        "        }\n",
        "    ],\n",
        "    \"experience\": [\n",
        "        {\n",
        "            \"title\": \"Software Engineer\",\n",
        "            \"company\": \"Tech Solutions Inc.\",\n",
        "            \"start_date\": \"June 2022\",\n",
        "            \"end_date\": \"Present\",\n",
        "            \"location\": \"San Francisco, CA\",\n",
        "            \"bullets\": [\n",
        "                \"Developed and maintained web applications using Python and Django.\",\n",
        "                \"Managed cloud infrastructure on AWS.\",\n",
        "                \"Collaborated with cross-functional teams.\"\n",
        "            ]\n",
        "        },\n",
        "         {\n",
        "            \"title\": \"Intern\",\n",
        "            \"company\": \"Data Analytics Corp.\",\n",
        "            \"start_date\": \"Summer 2021\",\n",
        "            \"end_date\": \"August 2021\",\n",
        "            \"location\": \"San Francisco, CA\",\n",
        "            \"bullets\": [\n",
        "                \"Assisted in data analysis projects.\",\n",
        "                \"Wrote scripts in Python.\",\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        "    \"projects\": [\n",
        "        {\n",
        "            \"name\": \"E-commerce Platform\",\n",
        "            \"technologies\": \"React, Node.js, MongoDB\",\n",
        "            \"description\": \"Built a full-stack e-commerce platform.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Sentiment Analysis Tool\",\n",
        "            \"technologies\": \"Python, TensorFlow\",\n",
        "            \"description\": \"Developed a machine learning model for sentiment analysis.\"\n",
        "        }\n",
        "    ],\n",
        "    \"skills\": [\"Python\", \"Django\", \"AWS\", \"React\", \"Node.js\", \"MongoDB\", \"TensorFlow\", \"SQL\", \"Docker\", \"Kubernetes\"]\n",
        "}\n",
        "\n",
        "try:\n",
        "    response = requests.post(f\"{api_url}/api/generate-resume\", json=resume_input_data)\n",
        "    response.raise_for_status() # Raise an exception for bad status codes\n",
        "    print(\"Response Status Code:\", response.status_code)\n",
        "    print(\"Response JSON:\")\n",
        "    print(json.dumps(response.json(), indent=2))\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error testing /api/generate-resume: {e}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- Test /api/generate-resume-pdf ---\n",
        "print(\"=\"*50)\n",
        "print(\"Testing /api/generate-resume-pdf (PDF download - requires manual check)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# This endpoint returns a PDF file. We will just check for a successful response.\n",
        "try:\n",
        "    response = requests.post(f\"{api_url}/api/generate-resume-pdf\", json=resume_input_data)\n",
        "    response.raise_for_status() # Raise an exception for bad status codes\n",
        "    print(\"Response Status Code:\", response.status_code)\n",
        "    print(\"Response Headers (check for Content-Disposition and Content-Type):\")\n",
        "    for header, value in response.headers.items():\n",
        "        print(f\"  {header}: {value}\")\n",
        "\n",
        "    # You can save the PDF content to a file to verify:\n",
        "    # with open(\"generated_resume.pdf\", \"wb\") as f:\n",
        "    #     f.write(response.content)\n",
        "    # print(\"\\nPDF content received.\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error testing /api/generate-resume-pdf: {e}\")\n",
        "\n",
        "print(\"\\nTesting complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Testing /api/analyze-job\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Oct/2025 08:51:07] \"POST /api/analyze-job HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response Status Code: 200\n",
            "Response JSON:\n",
            "{\n",
            "  \"keywords\": \"Engineer, Python, Django, contributing, cloud\",\n",
            "  \"keywords_list\": [\n",
            "    \"Engineer\",\n",
            "    \"Python\",\n",
            "    \"Django\",\n",
            "    \"contributing\",\n",
            "    \"cloud\"\n",
            "  ],\n",
            "  \"success\": true\n",
            "}\n",
            "\n",
            "\n",
            "==================================================\n",
            "Testing /api/generate-resume (JSON output)\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Oct/2025 08:51:47] \"POST /api/generate-resume HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response Status Code: 200\n",
            "Response JSON:\n",
            "{\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"Master of Science in Computer Science\",\n",
            "      \"gpa\": \"3.9\",\n",
            "      \"graduation_date\": \"May 2022\",\n",
            "      \"institution\": \"University of California, Berkeley\"\n",
            "    },\n",
            "    {\n",
            "      \"degree\": \"Bachelor of Science in Electrical Engineering\",\n",
            "      \"gpa\": \"3.8\",\n",
            "      \"graduation_date\": \"May 2020\",\n",
            "      \"institution\": \"Stanford University\"\n",
            "    }\n",
            "  ],\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"bullets\": [\n",
            "        \"Developed and maintained web applications utilizing Python and Django. Improved bullet point to be professional and impactful.\",\n",
            "        \"Enhanced managed cloud infrastructure on AWS. Improved bullet point to be professional and impactful.\",\n",
            "        \"Enhanced collaborated with cross-functional teams. Improved collaboration speed and efficiency.\"\n",
            "      ],\n",
            "      \"company\": \"Tech Solutions Inc.\",\n",
            "      \"end_date\": \"Present\",\n",
            "      \"location\": \"San Francisco, CA\",\n",
            "      \"start_date\": \"June 2022\",\n",
            "      \"title\": \"Software Engineer\"\n",
            "    },\n",
            "    {\n",
            "      \"bullets\": [\n",
            "        \"Enhanced assisted in data analysis projects. Improved bullet point:\",\n",
            "        \"Enhanced wrote scripts in Python. Improved bullet point to be professional and impactful.\"\n",
            "      ],\n",
            "      \"company\": \"Data Analytics Corp.\",\n",
            "      \"end_date\": \"August 2021\",\n",
            "      \"location\": \"San Francisco, CA\",\n",
            "      \"start_date\": \"Summer 2021\",\n",
            "      \"title\": \"Intern\"\n",
            "    }\n",
            "  ],\n",
            "  \"keywords_extracted\": [\n",
            "    \"Engineer\",\n",
            "    \"Python\",\n",
            "    \"Django\",\n",
            "    \"contributing\",\n",
            "    \"cloud\"\n",
            "  ],\n",
            "  \"match_score\": 40.0,\n",
            "  \"personal_info\": {\n",
            "    \"email\": \"jane.doe@example.com\",\n",
            "    \"linkedin\": \"linkedin.com/in/janedoe\",\n",
            "    \"location\": \"San Francisco, CA\",\n",
            "    \"name\": \"Jane Doe\",\n",
            "    \"phone\": \"123-456-7890\"\n",
            "  },\n",
            "  \"professional_summary\": \"Results-driven Software Engineer with 2+ years of experience leveraging Python and Django to deliver innovative solutions. Proven track record of improving efficiency and driving business outcomes through technical expertise.\",\n",
            "  \"projects\": [\n",
            "    {\n",
            "      \"description\": \"Developed full-stack e-commerce platform with React frontend and Node.js backend, integrating MongoDB payment processing for seamless transactions. Implemented user authentication, product catalog with search/filter functionality, and shopping cart system. Increased customer retention by 45% and improved order fulfillment speed by 50%.\",\n",
            "      \"name\": \"E-commerce Platform\",\n",
            "      \"technologies\": \"React, Node.js, MongoDB\"\n",
            "    },\n",
            "    {\n",
            "      \"description\": \"Developed predictive machine learning model for sentiment analysis using Python and TensorFlow. Performed data preprocessing, feature engineering, and hyperparameter tuning. Deployed model to production, enabling proactive retention strategies that reduced retention by 35%.\",\n",
            "      \"name\": \"Sentiment Analysis Tool\",\n",
            "      \"technologies\": \"Python, TensorFlow\"\n",
            "    }\n",
            "  ],\n",
            "  \"skills\": [\n",
            "    \"Python\",\n",
            "    \"Django\",\n",
            "    \"AWS\",\n",
            "    \"React\",\n",
            "    \"Node.js\",\n",
            "    \"MongoDB\",\n",
            "    \"TensorFlow\",\n",
            "    \"SQL\",\n",
            "    \"Docker\",\n",
            "    \"Kubernetes\"\n",
            "  ],\n",
            "  \"success\": true\n",
            "}\n",
            "\n",
            "\n",
            "==================================================\n",
            "Testing /api/generate-resume-pdf (PDF download)\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Oct/2025 08:52:26] \"POST /api/generate-resume-pdf HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response Status Code: 200\n",
            "PDF content received and saved to Resume_Jane_Doe_20251023.pdf\n",
            "\n",
            "Testing complete.\n"
          ]
        }
      ]
    }
  ]
}